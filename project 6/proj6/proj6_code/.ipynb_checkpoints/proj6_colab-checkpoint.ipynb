{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Dv8absVKufcA",
   "metadata": {
    "id": "Dv8absVKufcA"
   },
   "source": [
    "# Semantic Segmentation with Deep Learning: Training and Testing on Colab\n",
    "\n",
    "Insert the following Javascript snippet into your browser console so that your Colab runtime won't time out. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and type this on the console prompt. (for mac press Option+Command+I)\n",
    "```Javascript\n",
    "function ClickConnect(){\n",
    "    console.log(\"Clicked on connect button\"); \n",
    "    document.querySelector(\"colab-connect-button\").click()\n",
    "}\n",
    "setInterval(ClickConnect,60000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdweXW5Xqd6R",
   "metadata": {
    "id": "bdweXW5Xqd6R"
   },
   "source": [
    "Zip up your code locally with `python zip_for_colab.py`, and upload your `cv_proj6.zip` file. Hit refresh, then run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ah8PNwYTqM1G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah8PNwYTqM1G",
    "outputId": "37b569ff-8d07-44d1-c377-64c59873463f"
   },
   "outputs": [],
   "source": [
    "!unzip cv_proj6_colab.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0pf627lnqsTo",
   "metadata": {
    "id": "0pf627lnqsTo"
   },
   "source": [
    "Install the `proj6_code` module locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sEkEfbqNqxa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEkEfbqNqxa4",
    "outputId": "9bedd832-b787-4408-c90b-0fcc1d1b6c90"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-franchise",
   "metadata": {
    "id": "sensitive-franchise"
   },
   "source": [
    "Download ImageNet-pretrained ResNet-50:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-explosion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bound-explosion",
    "outputId": "5f868037-5acb-40ba-95eb-7d6e528d50b4"
   },
   "outputs": [],
   "source": [
    "!wget -O \"resnet50_v2.pth\" --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w5pRmLJXvmQQA5PtCbHhZc_uC4o0YbmA'\n",
    "!mkdir initmodel && mv resnet50_v2.pth initmodel/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yZDeFtlyuXNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZDeFtlyuXNz",
    "outputId": "bb3cd374-2407-4d76-e7ba-e79059d00a91"
   },
   "outputs": [],
   "source": [
    "# The ImageNet-pretrained ResNet-50 weights should be 99 MB\n",
    "!ls -ltrh initmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wzfFzyHupog",
   "metadata": {
    "id": "7wzfFzyHupog"
   },
   "source": [
    "Download the Camvid dataset images. It's 700 MB, but it should only take 30 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-delaware",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "intellectual-delaware",
    "outputId": "7079f327-3199-44c1-e494-73efc9398245"
   },
   "outputs": [],
   "source": [
    "!chmod +rwx download_dataset.sh\n",
    "!./download_dataset.sh Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGBUoTc9Aj0t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGBUoTc9Aj0t",
    "outputId": "8e0536ff-cc94-4976-f606-0146348f03ca"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "!cd Camvid && unzip camvid_semseg11.zip && cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AC_-gfRptGgF",
   "metadata": {
    "id": "AC_-gfRptGgF"
   },
   "source": [
    "We'll now set some default hyperparameters for training. Choose the number of epochs you'd like to train for (for PSPNet, it will take ~20-30 min for 50 epochs, or ~60 min for 100 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absent-major",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "absent-major",
    "outputId": "86019d3c-bd91-42c1-9e06-7a68f711f000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\r\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    **{\n",
    "        # DATA\n",
    "        \"names_path\": \"./dataset_lists/camvid-11/camvid-11_names.txt\",\n",
    "        \"data_root\": \"./Camvid/\",\n",
    "        \"train_list\": \"./dataset_lists/camvid-11/list/train.txt\",  \n",
    "        \"val_list\": \"./dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"classes\": 11,\n",
    "        # TRAIN\n",
    "        \"arch\": \"PSPNet\", #  \"SimpleSegmentationNet\", # Choose your architecture here\n",
    "        \"save_path\": \"\",\n",
    "        \"epochs\": 50, # Choose your desired number of epochs here\n",
    "        \"zoom_factor\": 8,\n",
    "        \"aux_weight\": 0.4,\n",
    "        \"layers\": 50,\n",
    "        \"workers\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"batch_size_val\": 32,\n",
    "        \"short_size\": 240,\n",
    "        \"train_h\": 201,\n",
    "        \"train_w\": 201,\n",
    "        \"init_weight\": \"../initmodel/resnet50_v2.pth\",\n",
    "        \"scale_min\": 0.5,  # minimum random scale\n",
    "        \"scale_max\": 2.0,  # maximum random scale\n",
    "        \"rotate_min\": -10,  # minimum random rotate\n",
    "        \"rotate_max\": 10,  # maximum random rotate\n",
    "        \"ignore_label\": 255,\n",
    "        \"base_lr\": 0.01,\n",
    "        \"start_epoch\": 0,\n",
    "        \"power\": 0.9,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"manual_seed\": 0,\n",
    "        \"print_freq\": 10,\n",
    "        \"save_freq\": 1,\n",
    "        \"evaluate\": True,  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend\n",
    "        \"multiprocessing_distributed\": False,\n",
    "        # INFERENCE\n",
    "        \"dataset\": \"camvid-11\",\n",
    "        \"base_size\": 720,\n",
    "        \"test_h\": 201,\n",
    "        \"test_w\": 201,\n",
    "        \"scales\": [1.0], # [0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        \"test_list\": \"./dataset_lists/camvid-11/list/val.txt\",\n",
    "        \"vis_freq\": 10,\n",
    "        \"pretrained\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "args.save_path = f\"exp/camvid/{args.arch}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "increased-blade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "increased-blade",
    "outputId": "be097290-c24a-44d2-b6d5-c2399f88d883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(arch='PSPNet', aux_weight=0.4, base_lr=0.01, base_size=720, batch_size=32, batch_size_val=32, classes=11, data_root='./Camvid/', dataset='camvid-11', epochs=50, evaluate=True, ignore_label=255, init_weight='../initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./dataset_lists/camvid-11/list/train.txt', train_w=201, val_list='./dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n",
      "namespace(arch='PSPNet', aux_weight=0.4, base_lr=0.01, base_size=720, batch_size=32, batch_size_val=32, classes=11, data_root='./Camvid/', dataset='camvid-11', epochs=50, evaluate=True, ignore_label=255, init_weight='../initmodel/resnet50_v2.pth', layers=50, manual_seed=0, momentum=0.9, multiprocessing_distributed=False, names_path='./dataset_lists/camvid-11/camvid-11_names.txt', power=0.9, pretrained=True, print_freq=10, rotate_max=10, rotate_min=-10, save_freq=1, save_path='exp/camvid/PSPNet/model', scale_max=2.0, scale_min=0.5, scales=[1.0], short_size=240, start_epoch=0, test_h=201, test_list='./dataset_lists/camvid-11/list/val.txt', test_w=201, train_h=201, train_list='./dataset_lists/camvid-11/list/train.txt', train_w=201, val_list='./dataset_lists/camvid-11/list/val.txt', vis_freq=10, weight_decay=0.0001, workers=2, zoom_factor=8)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './initmodel/resnet50_v2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-195a51d8935d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mproj6_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmain_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/CS 6476/project 6/proj6/proj6_code/trainer.py\u001b[0m in \u001b[0;36mmain_worker\u001b[0;34m(args, use_cuda)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m\"\"\" \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_and_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=> creating model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS 6476/project 6/proj6/proj6_code/part3_training_utils.py\u001b[0m in \u001b[0;36mget_model_and_optimizer\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PSPNet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         model = PSPNet(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CS 6476/project 6/proj6/proj6_code/part5_pspnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, bins, dropout, num_classes, zoom_factor, use_ppm, criterion, pretrained, deep_base)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         self.layer0 = nn.Sequential(\n",
      "\u001b[0;32m~/Desktop/CS 6476/project 6/proj6/proj6_code/resnet.py\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./initmodel/resnet50_v2.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs6476_proj6/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs6476_proj6/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs6476_proj6/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './initmodel/resnet50_v2.pth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "from proj6_code.trainer import main_worker\n",
    "print(args)\n",
    "main_worker(args, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7or_wjTqvX6H",
   "metadata": {
    "id": "7or_wjTqvX6H"
   },
   "source": [
    "We'll now create full-resolution predictions for the full val set, and compute mIoU against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-vegetation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "worst-vegetation",
    "outputId": "08decf88-2270-4dde-f313-fe2cd75d9dc0"
   },
   "outputs": [],
   "source": [
    "from proj6_code.test import test_model\n",
    "args.model_path = f\"exp/camvid/{args.arch}/model/train_epoch_{args.epochs}.pth\"\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ETWCIkf1vfCP",
   "metadata": {
    "id": "ETWCIkf1vfCP"
   },
   "source": [
    "**Important**: Record the mIoU listed in the output above, and the IoU per each class. You can find the results later in `train_epoch_{args.epochs}/camvid-11/720/results.txt`.\n",
    "\n",
    "Now, let's take a look at what our results look like. We'll make a 2x3 image grid with the following structure:\n",
    "\n",
    "|RGB Image | Blended RGB and Ground Truth | Ground Truth \n",
    "|:-: | :-: | :-:\n",
    "| RGB Image | Blended RGB and Prediction | Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cDpIrDQvvBq5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "cDpIrDQvvBq5",
    "outputId": "b63a39b7-04a5-42f8-cc9d-88fb2468c6ab"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rgb_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/rgb_mask_predictions\"\n",
    "\n",
    "def show_image_grid(rgb_predictions_dir: str, img_fname: str) -> None:\n",
    "  img_grid = imageio.imread(f'{rgb_predictions_dir}/{img_fname}')\n",
    "  plt.figure(figsize=(15,7))\n",
    "  plt.imshow(img_grid)\n",
    "  plt.show()\n",
    "\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_07977.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JOxOOpJ-wDHa",
   "metadata": {
    "id": "JOxOOpJ-wDHa"
   },
   "source": [
    "We'll look at more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wJo0THuZvDkU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJo0THuZvDkU",
    "outputId": "790b3875-5df5-46f4-b9c2-0320e01d22b3"
   },
   "outputs": [],
   "source": [
    "show_image_grid(rgb_predictions_dir, \"0016E5_07997.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08017.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08037.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08057.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08077.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08097.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08117.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08137.jpg\")\n",
    "show_image_grid(rgb_predictions_dir, \"0016E5_08157.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e-fziKDH1XlL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "e-fziKDH1XlL",
    "outputId": "dfa440b9-49e1-4f73-f4a5-7a16aa97b68a"
   },
   "outputs": [],
   "source": [
    "while True:pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VFCSB5B23t19",
   "metadata": {
    "id": "VFCSB5B23t19"
   },
   "source": [
    "Now, zip up your predictions on the test set for your best model, **download them locally to your machine**, and submit these to Gradescope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VbYbqcNn3eS2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbYbqcNn3eS2",
    "outputId": "85f5c7aa-3e2e-48b3-cd31-bc255e8160ef"
   },
   "outputs": [],
   "source": [
    "grayscale_predictions_dir = f\"train_epoch_{args.epochs}/camvid-11/{args.base_size}/gray\"\n",
    "!ls -ltrh $grayscale_predictions_dir\n",
    "!zip -r grayscale_predictions.zip $grayscale_predictions_dir\n",
    "!ls -ltrh grayscale_predictions.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foAbZe_L38S9",
   "metadata": {
    "id": "foAbZe_L38S9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "proj6_colab2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
